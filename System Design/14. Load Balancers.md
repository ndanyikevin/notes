
---

## 🧱 What Is a Load Balancer?

A **load balancer** is a **traffic manager** that distributes incoming network requests (like user visits) **across multiple servers** to make sure no single server is overloaded.

It acts as the “front door” of your system — receiving all requests first, then deciding **which backend server** should handle each request.

---

### 🧩 Simple Definition

> A **load balancer** evenly distributes user requests across multiple servers to improve performance, reliability, and availability.

---

## 💡 Analogy

Imagine your school’s reception desk:

- Students come to ask for services.
    
- The receptionist (load balancer) checks which teacher or office is **free**.
    
- Then sends each student to the available teacher.
    

If one teacher is busy or absent, the receptionist directs students to others — so work never stops.

That receptionist = **Load Balancer**  
Teachers = **Servers**  
Students = **Requests**

---

## ⚙️ How It Works (Simplified)

```
        Internet Users
              ↓
        ┌──────────────┐
        │ Load Balancer│
        └──────┬───────┘
               │
 ┌─────────────┴─────────────┐
 │                           │
▼                           ▼
Server A                 Server B
(Handles some requests)  (Handles others)
```

Each server processes fewer requests, so:

- The app stays **fast** 🏃‍♂️
    
- No server gets **overloaded** 💥
    
- If one fails, others **take over** 💪
    

---

## ⚙️ Load Balancing Algorithms (How it decides who gets what)

|Algorithm|Description|
|---|---|
|**Round Robin**|Sends requests to servers in turn (A → B → C → A …)|
|**Least Connections**|Sends new request to server with the fewest active connections|
|**IP Hash**|Sends a user’s requests always to the same server (based on IP)|
|**Weighted Round Robin**|Gives more traffic to powerful servers|
|**Random**|Randomly assigns requests to servers|

---

## 🧩 Types of Load Balancers

|Type|Works At|Description|
|---|---|---|
|**Layer 4 (Transport Layer)**|TCP/UDP|Routes traffic based on IP and port|
|**Layer 7 (Application Layer)**|HTTP/HTTPS|Routes traffic based on content (e.g., URL, headers, cookies)|
|**Global Load Balancer (DNS-based)**|Internet-wide|Routes users to nearest data center geographically|

---

## ☁️ Load Balancers in AWS

|AWS Service|Type|Description|
|---|---|---|
|**Elastic Load Balancer (ELB)**|General|AWS-managed load balancer|
|**Application Load Balancer (ALB)**|Layer 7|Routes based on HTTP/S path, hostname, etc.|
|**Network Load Balancer (NLB)**|Layer 4|Very fast, handles millions of requests per second|
|**Gateway Load Balancer (GLB)**|Network|Used with firewalls or security tools|

---

## 🧩 Example: School Management System

### Without Load Balancer

```
Users → Server A
```

If Server A fails → the whole system goes down ❌

### With Load Balancer

```
Users → Load Balancer → [Server A, Server B, Server C]
```

- Requests are shared evenly.
    
- If Server A fails, traffic goes to B and C.
    
- Users never notice downtime ✅
    

---

## 📈 Benefits

✅ **High availability** — if one server fails, others keep running  
✅ **Scalability** — easily add or remove servers  
✅ **Improved performance** — distributes load evenly  
✅ **Health checks** — monitors servers and removes unhealthy ones automatically  
✅ **Flexibility** — can route requests by type (e.g., `/api` → backend, `/images` → static server)

---

## ⚠️ Drawbacks

❌ **Single point of failure** (unless you use multiple load balancers)  
❌ **Added latency** (slight delay due to routing)  
❌ **Configuration complexity** (requires setup and monitoring)

---

## 🧮 Quick Summary

|Concept|Description|
|---|---|
|**Definition**|Device/service that distributes network traffic among servers|
|**Main Goal**|Prevent overload and ensure availability|
|**Used In**|Horizontal scaling, high availability systems|
|**Common Algorithms**|Round robin, least connections, IP hash|
|**Cloud Example**|AWS Application Load Balancer (ALB)|

---

## 🚀 Real Example in AWS

When building your **school management system**:

1. Use **AWS Application Load Balancer (ALB)** to distribute user requests.
    
2. Have **3 EC2 instances** running your app in an **Auto Scaling Group**.
    
3. If traffic increases, AWS automatically adds more instances.
    
4. ALB sends requests to the new instances.
    

Result:

- Your app stays fast and online even if one instance crashes.
    

---
